You can use Python's multiprocessing module to run these two tasks concurrently. Here is an example of how you can modify your script to use multiprocessing:

```python
import multiprocessing
from dash import Dash
import dash_bootstrap_components as dbc
import db
import hp
import fd

def run_dash():
    app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
    database=db.dataBase()
    homepage=hp.homepage(database)
    homepage.timeUpdateCallback(app)
    homepage.gaugeRefreshCallback(app)
    app.layout = homepage.layoutMaker()
    app.run_server(debug=True)

def run_data_mining():
    database=db.dataBase()
    dataMiningScript= fd.financeData(database,1600)

if __name__ == "__main__":
    # Create processes
    p1 = multiprocessing.Process(target=run_dash)
    p2 = multiprocessing.Process(target=run_data_mining)

    # Start processes
    p1.start()
    p2.start()

    # Join processes
    p1.join()
    p2.join()
```

This script creates two separate processes, one for the Dash server and one for the data mining script. Each process will run independently of the other, allowing them to both run in an infinite loop without blocking each other.

Please note that multiprocessing has its own set of challenges and may not be suitable for all use cases. For example, sharing data between processes can be more complex than with threads. In your case, as long as the database handles concurrent writes and reads correctly, you should be fine.